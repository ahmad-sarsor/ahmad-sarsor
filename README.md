# dbt Analytics Data Warehouse

Welcome to the **dbt Analytics Data Warehouse** repository! ğŸš€  
This project demonstrates a production-grade data warehouse built with dbt Core and BigQuery, featuring 107+ models for tech ecosystem analytics. Designed as a portfolio project, it highlights industry best practices in modern data engineering and analytics engineering.

---

## ğŸ—ï¸ Data Architecture

The data architecture for this project follows the **Three-Layer dbt Architecture** with Google Cloud Build orchestration:

![Data Architecture](docs/data_architecture.png)

1. **Staging Layer**: Raw data connection from source systems. Light transformations including column renaming, type casting, and basic filtering. Data is stored as Views.
2. **Intermediate Layer**: Business logic transformations including data cleansing, joining entities, business rules, calculated fields, and data enrichment. Data Model is Normalized.
3. **Marts Layer**: Business-ready analytics with star schema design. Includes data integration, aggregations, KPI calculations, and final metrics for reporting.

---

## ğŸ“– Project Overview

This project involves:

1. **Data Architecture**: Designing a Modern Data Warehouse using dbt's three-layer architecture (Staging â†’ Intermediate â†’ Marts).
2. **ELT Pipelines**: Extracting data from multiple sources and transforming with dbt Core on BigQuery.
3. **Data Modeling**: Developing fact and dimension tables using dimensional modeling best practices.
4. **Data Quality**: Implementing comprehensive testing, documentation, and real-time monitoring.
5. **CI/CD**: Automated deployment with Google Cloud Build, Cloud Run, and Cloud Scheduler.
6. **Analytics & Reporting**: Powering Power BI dashboards and organizational reports.

ğŸ¯ This repository is an excellent resource for professionals looking to showcase expertise in:
- Analytics Engineering
- dbt Development
- Data Engineering  
- Data Modeling  
- BigQuery & GCP
- CI/CD for Data

---

## ğŸ› ï¸ Important Links & Tools

Everything you need to understand and replicate this project:

- **[dbt Core](https://docs.getdbt.com/):** Data transformation framework
- **[Google BigQuery](https://cloud.google.com/bigquery):** Cloud data warehouse
- **[Google Cloud Build](https://cloud.google.com/build):** CI/CD orchestration
- **[Power BI](https://powerbi.microsoft.com/):** Business intelligence and reporting
- **[Draw.io](https://www.drawio.com/):** Design data architecture and diagrams
- **[Git Repository](https://github.com/):** Version control and collaboration

---

## ğŸš€ Project Requirements

### Building the Data Warehouse (Data Engineering)

#### Objective
Develop a modern data warehouse using dbt Core and BigQuery to consolidate tech ecosystem data, enabling analytical reporting and informed decision-making.

#### Specifications
- **Data Sources**: Import data from multiple source systems (MySQL, Google Analytics 4, APIs) via BigQuery Federation.
- **Data Quality**: Cleanse and resolve data quality issues using dbt tests and custom validations.
- **Integration**: Combine all sources into a single, user-friendly data model designed for analytical queries.
- **Automation**: Daily scheduled refreshes with Cloud Scheduler and Cloud Run.
- **Documentation**: Provide clear documentation of the data model using dbt docs.

---

### BI: Analytics & Reporting (Data Analysis)

#### Objective
Develop analytics models to deliver detailed insights into:
- **Funding Trends**: Investment rounds, amounts, and sectors
- **Company Performance**: Growth metrics and sector analysis
- **Investor Analysis**: Active investors and participation patterns
- **Economic Indicators**: GDP contribution and employment trends

These insights empower stakeholders with key business metrics for the Israeli Tech Ecosystem reports.

---

## ğŸ“‚ Repository Structure

```
dbt-analytics-dwh/
â”‚
â”œâ”€â”€ models/                              # dbt models organized by layer
â”‚   â”œâ”€â”€ staging/                         # Raw data transformations (30+ models)
â”‚   â”‚   â”œâ”€â”€ mysql/                       # Models from MySQL source
â”‚   â”‚   â”œâ”€â”€ google_sheets/               # Models from Google Sheets
â”‚   â”‚   â”œâ”€â”€ ga4/                         # Models from Google Analytics 4
â”‚   â”‚   â””â”€â”€ staging.yml                  # Schema definitions
â”‚   â”‚
â”‚   â”œâ”€â”€ intermediate/                    # Business logic layer (40+ models)
â”‚   â”‚   â”œâ”€â”€ entities/                    # Entity transformations
â”‚   â”‚   â”œâ”€â”€ metrics/                     # Calculated metrics
â”‚   â”‚   â””â”€â”€ intermediate.yml             # Schema definitions
â”‚   â”‚
â”‚   â””â”€â”€ marts/                           # Business-ready models (35+ models)
â”‚       â”œâ”€â”€ core/                        # Core dimensions and facts
â”‚       â”œâ”€â”€ finance/                     # Finance-specific models
â”‚       â”œâ”€â”€ marketing/                   # Marketing models
â”‚       â””â”€â”€ marts.yml                    # Schema definitions
â”‚
â”œâ”€â”€ tests/                               # Custom data tests
â”‚   â”œâ”€â”€ generic/                         # Reusable test definitions
â”‚   â””â”€â”€ singular/                        # One-off test queries
â”‚
â”œâ”€â”€ macros/                              # Reusable Jinja macros
â”‚
â”œâ”€â”€ seeds/                               # Static reference data (CSV)
â”‚
â”œâ”€â”€ snapshots/                           # Slowly changing dimensions
â”‚
â”œâ”€â”€ docs/                                # Project documentation
â”‚   â”œâ”€â”€ data_architecture.png            # Architecture diagram
â”‚   â”œâ”€â”€ erd_diagram.png                  # Entity Relationship Diagram
â”‚   â””â”€â”€ data_catalog.md                  # Field descriptions and metadata
â”‚
â”œâ”€â”€ scripts/                             # Deployment and utility scripts
â”‚   â”œâ”€â”€ deploy/                          # Cloud Run deployment
â”‚   â””â”€â”€ alerts/                          # Slack notification scripts
â”‚
â”œâ”€â”€ dbt_project.yml                      # dbt project configuration
â”œâ”€â”€ packages.yml                         # dbt package dependencies
â”œâ”€â”€ profiles.yml.example                 # Example connection profile
â”œâ”€â”€ Dockerfile                           # Container configuration
â”œâ”€â”€ README.md                            # Project documentation
â”œâ”€â”€ LICENSE                              # License information
â””â”€â”€ .gitignore                           # Git ignore rules
```

---

## ğŸ“Š Data Flow Summary

| Layer | Object Type | Materialization | Models | Prefix |
|-------|-------------|-----------------|--------|--------|
| **Staging** | Views | View | 30+ | `stg_` |
| **Intermediate** | Tables | Table / Incremental | 40+ | `int_` |
| **Marts** | Tables | Table | 35+ | `dim_` / `fct_` |

---

## ğŸ”§ Tech Stack

| Category | Technology |
|----------|------------|
| **Transformation** | dbt Core |
| **Data Warehouse** | Google BigQuery |
| **Orchestration** | Google Cloud Build, Cloud Run, Cloud Scheduler |
| **BI & Reporting** | Power BI |
| **Version Control** | Git, GitHub |
| **Data Sources** | MySQL (CloudSQL), Google Analytics 4, APIs |

---

## ğŸš€ Getting Started

### Prerequisites
- Python 3.9+
- dbt Core 1.7+
- Google Cloud SDK
- BigQuery access

### Installation

```bash
# Clone the repository
git clone https://github.com/ahmad-sarsor/dbt-analytics-dwh.git
cd dbt-analytics-dwh

# Create virtual environment
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt

# Configure dbt profile
cp profiles.yml.example ~/.dbt/profiles.yml

# Verify installation
dbt debug
```

### Running the Project

```bash
# Install dbt packages
dbt deps

# Run all models
dbt run

# Run tests
dbt test

# Generate documentation
dbt docs generate
dbt docs serve
```

---

## ğŸ›¡ï¸ License

This project is licensed under the [MIT License](LICENSE). You are free to use, modify, and share this project with proper attribution.

---

## ğŸŒŸ About Me

Hi there! I'm **Ahmad Sarsor**, a BI & Data Engineer with expertise in building end-to-end cloud-based data infrastructure and analytics solutions. Specialized in dbt Core, BigQuery, and Google Cloud Platform.

[![LinkedIn](https://img.shields.io/badge/LinkedIn-0077B5?style=for-the-badge&logo=linkedin&logoColor=white)](https://www.linkedin.com/in/ahmad-sarsor/)
[![GitHub](https://img.shields.io/badge/GitHub-100000?style=for-the-badge&logo=github&logoColor=white)](https://github.com/ahmad-sarsor)
[![Email](https://img.shields.io/badge/Email-D14836?style=for-the-badge&logo=gmail&logoColor=white)](mailto:ahmad.kefah11sar@gmail.com)
